%!TEX encoding = UTF-8 Unicode

\section{Related Work}
\label{sec:related_work}

NEW PARAGRAPH FOLLOWING THE ORDER OF THE INTRODUCTION -
Human cooperation is a phenomenon that we often take for granted~(at least in adults), possibly because it is widespread and intimately embedded into human societies.
It is reasonable to say that this skill is greatly facilitated, and influenced, by human language~(i.e., a highly elaborated, complex yet efficient communication system) TODO ADD REF. cite work on robotics, language and gestures~\cite{matuszek:2014:aaai}).
TODO literature about children, adults, neuroscience of collaboration.
Educational research has shown that, when language is used as a cultural tool for intellectual tasks in preteen students, discursive interaction enables collective thinking to become more effective, also fostering individual reasoning and faster learning~\cite{rojas:2003:ijer}. % related: leman:2000 (age 7--9)
as well as the    the need to ground~\cite{harnad:1990} spoken language to environment elements, which is useful both for receiving human commands or for describing what is happening in natural language~\cite{steels:2003:trendscogsci}.
% dev rob
In this line of research, which we follow, robots are experimental platforms.
They are used to verify theoretical models of emergence and development of cognition.
The rationale is the following: if a model is instantiated inside a system physically embedded in the real world, many things can be learned about its strengths and limitations.
This is often accompanied by probabilistic and statistical methods~\cite{pearl:2014:probabilistic}.

% HRC, mirror/correspondence
The ability to understand and interpret our peers has also been studied in neuroscience research, focusing on visuomotor neurons~\cite{rizzolatti:2001:nrn}: neurons that are activated by visual stimuli.
Mirror neurons are one class of such neurons that responds to action and object interaction, both when the agent acts and when it observes the same action performed by others, hence the name ``mirror''.
Applying the mirror neuron theory in robotics, as we and others do TODO ADD REFS, an agent can first acquire knowledge by sensing and self-exploring its surrounding environment, %~(e.g., by interacting with available objects and building up an affordance representation of the interactions and their outcomes)
afterwards it can employ that learned knowledge to novel observations of another agent~(e.g., a human person) who performs similar physical actions to the ones executed during prior training.
This tackles the so-called correspondence problem~\cite{nehaniv:2002:correspondence} in a simple collaboration scenario, assuming that the two agents have a similar body~(i.e., a humanoid robot and a human) and operate on a shared space~(i.e., a table accessible by both agents' arms).

A large body of neuroscience and psychology studies build upon this theory, based on the principle that perceptual input can be linked with the human action system for predicting future outcomes of actions, i.e., the effect of actions, particularly when the person possesses concrete prior personal experience of the actions being observed in others~\cite{aglioti:2008:basketball,knoblich:2001:psychsci}.
This has also been exploited under the deep learning paradigm~\cite{kim:2017:nn}, by using a \ac{MTRNN} to have an artificial simulated agent infer human intention from joint information about object affordances and human actions.
One difference between this line of research and ours is that we use real, noisy data acquired from robots and sensors to test our models~(we also make the data publicly available), instead of virtual simulations which, by nature, cannot model all the physical events and unpredictability of the real world.

% robot affordances
In robotics literature, a growing interest is devoted to robots that learn new cognitive skills and improve their capabilities by interacting autonomously with the surrounding environment.
Robots operating in the unstructured world may understand available opportunities conditioned on their body, perception and sensorimotor experiences: the intersection of these elements gives rise to object \emph{affordances}~(action possibilities), as they are called in psychology~\cite{gibson:2014}.
The advantage of robot affordances lies in the ability to capture essential functional properties of environment objects in terms of the actions that the agent is able to perform with them, allowing to generalize knowledge to never-before-seen scenarios, thus exhibiting learning~\cite{montesano:2008,jamone:2016:tcds}.
Some authors have suggested a computational model called \acp{OAC}~\cite{kruger:2011:ras}, which links low-level sensorimotor knowledge with high-level symbolic reasoning and planning in autonomous robots.

% robot affordances + language
Several works have studied the potential coupling between learning robot affordances and \emph{language grounding}.
The union of these two elements can give new skills to cognitive robots, such as learning the association of spoken words with sensorimotor experience~\cite{salvi:2012:smcb,morse:2016:cogsci}, linking language with sensorimotor representations~\cite{stramandinoli:2016:icdl},% learning tool use capabilities~\cite{goncalves:2014:icarsc,goncalves:2014:icdl},
or carrying out complex %manipulation
tasks~(which require planning of a sequence of actions) expressed in natural language instructions to a robot~\cite{antunes:2016:icra}.

In particular~\cite{salvi:2012:smcb}, which this paper extends, proposes a joint model is proposed to learn robot affordances~(i.e., relationships between actions, objects and resulting effects) together with word meanings.
The data used for learning such a model is from robot manipulation experiments, acquired from an ego-centric perspective.
Each experiment is associated with a number of alternative verbal descriptions uttered by two human speakers, for a total of \SI{1270}~recordings.
That framework assumes that the robot action is known a~priori during the training phase~(e.g., the information ``grasping'' during a grasping experiment is given), and the resulting model can be used at testing to make inferences about the environment, including estimating the most likely action, based on evidence from other pieces of information.
However,~\cite{salvi:2012:smcb} assumed that the robot action was known during training.
In a recent work~\cite{saponaro:2017:glu} we have relaxed that assumption, merging the action estimation obtained from an external gesture recognizer~\cite{saponaro:2013:crhri} as a \emph{hard evidence} to the full model, meaning that the action was deterministic.
By contrast, in this paper we propose a theoretical way to fuse the two sources of information~(about the self and about others) in a fully probabilistic manner, therefore introducing the \emph{soft evidence}.
This addition allows to perform more fine-grained types of inferences and reasoning.% with our full model that now combines affordances, words and gestures.
First, predictions over affordances and words when observing another agent.
Secondly, the generation of \emph{verbal descriptions} from the estimated word probabilities, for easier human interpretation of the model's explanations.
%We show how the model possesses the property of distinguishing between congruent/incongruent conjunctions, and subject words being coherently repeated between two consecutive sentences that refer to the same concepts. % TODO move this elsewhere

TODO literature about theory/probabilistic inference? such as pan:2006:ictai \cite{pan:2006:ictai}

%BELOW IS THE GLU TEXT

%A large and growing body of research is directed towards having robots learn new cognitive skills, or improving their capabilities, by interacting autonomously with their surrounding environment.
%In particular, robots operating in an unstructured scenario may understand available opportunities conditioned on their body, perception and sensorimotor experiences: the intersection of these elements gives rise to object affordances~(action possibilities), as they are called in psychology~\cite{gibson:2014}.
%The usefulness of affordances in cognitive robotics is in the fact that they capture essential properties of environment objects in terms of the actions that a robot is able to perform with them~\cite{montesano:2008,jamone:2016:tcds}.
%Some authors have suggested an alternative computational model called \acp{OAC}~\cite{kruger:2011:ras}, which links low-level sensorimotor knowledge with high-level symbolic reasoning hierarchically in autonomous robots.

% In addition, several works have demonstrated how combining robot affordance learning with language grounding can provide cognitive robots with new and useful skills, such as learning the association of spoken words with sensorimotor experience~\cite{salvi:2012:smcb,morse:2016:cogsci} or sensorimotor representations~\cite{stramandinoli:2016:icdl}, learning tool use capabilities~\cite{goncalves:2014:icarsc,goncalves:2014:icdl}, and carrying out complex manipulation tasks expressed in natural language instructions which require planning and reasoning~\cite{antunes:2016:icra}.

% In~\cite{salvi:2012:smcb}, a joint model is proposed to learn robot affordances~(i.e., relationships between actions, objects and resulting effects) together with word meanings. The data contains robot manipulation experiments, each of them associated with a number of alternative verbal descriptions uttered by two speakers for a total of \SI{1270}~recordings. That framework assumes that the robot action is known a~priori during the training phase~(e.g., the information ``grasping'' during a grasping experiment is given), and the resulting model can be used at testing to make inferences about the environment, including estimating the most likely action, based on evidence from other pieces of information.

%Several neuroscience and psychology studies build upon the theory of mirror neurons which we brought up in the Introduction. These studies indicate that perceptual input can be linked with the human action system for predicting future outcomes of actions, i.e., the effect of actions, particularly when the person possesses concrete personal experience of the actions being observed in others~\cite{aglioti:2008:basketball,knoblich:2001:psychsci}. This has also been exploited under the deep learning paradigm~\cite{kim:2017:nn}, by using a \ac{MTRNN} to have an artificial simulated agent infer human intention from joint information about object affordances and human actions. One difference between this line of research and ours is that we use real, noisy data acquired from robots and sensors to test our models, rather than virtual simulations.
